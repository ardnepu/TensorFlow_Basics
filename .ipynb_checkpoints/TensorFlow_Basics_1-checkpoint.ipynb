{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beingaerys/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, what we do is first create a graph of nodes and then pass the data from one node to another in the form of tensors (multidimensional arrays). Thus, flow of tensors.A tensorflow program has 2 parts: building a computational graph and then running this computational graph. A computational graph is a series of tensorflow operations (an operation can simply be a value or some mathematical calculation) representaed as nodes.\n",
    "\n",
    "\n",
    "<img src=\"Computational-Graph-TensorFlow.png\">\n",
    "\n",
    "\n",
    "Image Source : Edureka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "#lets build a graph with three nodes\n",
    "node1 = tf.constant(5)\n",
    "node2 = tf.constant(10)\n",
    "multiplication_node = node1 * node2\n",
    "\n",
    "#run the graph in a session by passing the tensor\n",
    "sess = tf.Session()\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(multiplication_node)\n",
    "    print (output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonetheless, we can visualize our TensorFlow graphs using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "File_Writer = tf.summary.FileWriter('graph',sess.graph) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tensorboard --logdir=\"graph\" where graph is the folder that contains the generated graph and you are in the working directory.\n",
    "\n",
    "Now,lets look at the types of nodes in TensorFlow.\n",
    "Above, we used node1 and node2 to store constant values. These nodes are called constant nodes that always produce  constant results i.e., when we execute a constant node, it always returns the value kept inside that node (here 5 and 10).\n",
    "\n",
    "However, what if we want to feed some input to our computation graph rather than directly putting some value at that node such that we can assign different input values to those nodes as our requirement. For this, we can use a type of node called a placeholder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7.]\n"
     ]
    }
   ],
   "source": [
    "node4 = tf.placeholder(tf.float32)\n",
    "node5 = tf.placeholder(tf.float32)\n",
    "addition_node = node4 + node5\n",
    "sess = tf.Session()\n",
    "print(sess.run(addition_node, {node4:[1,2],node5:[4,5]}))\n",
    "File_Writer = tf.summary.FileWriter('graph',sess.graph) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand this: Once we place a value in a placeholder, we cannot update its value. However, in Machine Learning, we might have\n",
    "an equation like y = wx + b where w is the weight and b is the bias. So, while we have a single input matrix for the field x in the equation above, we need to run multiple iterations of w and b so as to get the optimal value of w and b for our problem. Thus, while a placeholder is enough to input the matrix once in the x field, we need a type of field in tensorflow where we can change the values at run time to eventually find out the optimal value. For this, we have a type of node called a variable in TensorFlow. a variable field's value can be changed as many times as we want at runtime. NOTE: VARIABLES NEED TO BE INITIALIZED AT THE INSTANT OF CREATION IN TENSORFLOW. However, we need to call a special line of code in TensorFlow explicity for this as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8. 13. 18. 23.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable([5.0],tf.float32)\n",
    "b = tf.Variable([3.0],tf.float32)\n",
    "\n",
    "init = tf.global_variables_initializer() #special line of code\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = w*x + b\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(linear_model,{x : [1,2,3,4]}))\n",
    "File_Writer = tf.summary.FileWriter('graph',sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we passed 4 values as x and got 4 outputs from the linear equation. However, in Machine Learning, what we do is we pass a matrix as an input X and allow the machine to provide us with the best fit for b and w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907.50995\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable([6.0],tf.float32)\n",
    "b = tf.Variable ([0.3],tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "linear_model = w * x + b\n",
    "\n",
    "#lets calculate the difference between the real output and the model output to calculate the loss in terms of MSE\n",
    "squared_error = tf.square(linear_model - y)\n",
    "summed_error = tf.reduce_sum(squared_error)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "ses = tf.Session()\n",
    "ses.run(init)# special line of code\n",
    "print(ses.run(summed_error,{x : [1,2,3,4], y : [0.1,2,2,2]}))\n",
    "#File_Writer = tf.summary.FileWriter('graph',sess.graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above what we have done is fed a Tensor of length 4 for both x and y such that only a simple mathematical computation has come forward. We can see that the loss is 907.509. We can decrease the loss by varying the values of w and b. However, this is not Machine Learning. What we want to do is allow our machine to calculate the optimal values for w and b such that the loss (summed error here) is minimal for our problem. This will then become the REAL machine learning. For this, what our computer will do is train the model (I hope you understand what training a model means)for a certain number of iterations such that it finds out the optimal value of the parameters (here b and w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w = tf.Variable([6.0],tf.float32)\n",
    "b = tf.Variable ([0.3],tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "linear_model = w * x + b\n",
    "\n",
    "#lets calculate the difference between the real output and the model output to calculate the loss in terms of MSE\n",
    "squared_error = tf.square(linear_model - y)\n",
    "summed_error = tf.reduce_sum(squared_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the best parameters for our equation y = w*x + b such that our summed_error is minimum\n",
    "Till now we had no way to automatically allow the program to run different iterations of b and w\n",
    "Lets use gradient descent optimization algorithm for this (Learn what Gradient descent is from Andrew Ng's videos)\n",
    "Remember that when you learned from Data School, you used KNN which needed random values of k just like we are \n",
    "needing random values of w and b here. There, we used GridSearchCV and RandomizedCV where the iterations of k ranged from 0 to a certain number (31).\n",
    "However, we will be using Gradient Descent here such that even in 1000 iterations, we won't ourselves define the values of w and b and thus will not be random but rather directed by mathematical derivative toward the minimum error. However, note that we could have provided 1000 different ( b,w) pairs instead of using Gradient descent but that would not have been the optimal way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.0000043], dtype=float32), array([0.9999875], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01) #defining an optimizer for training\n",
    "train = optimizer.minimize(summed_error) \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)# special line of code\n",
    "for i in range (1000):\n",
    "    sess.run(train, { x : [1,2,3,4], y : [2,3,4,5]})#training the model using gradient descent optimization as well\n",
    "    \n",
    "print (sess.run([w,b]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
